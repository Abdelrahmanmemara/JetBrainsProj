{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Corrector\n",
    "\n",
    "- We use Birbeck dataset, as it gives us a large and versatile combination of data to test the chosen models.\n",
    "\n",
    "- We will work a pre-trained model and analyze its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1:- CHOOSING AND MODIFYING THE DATASET\n",
    "\n",
    "- We choose the Birbeck dataset due to its large and diverse combination of words. \n",
    "\n",
    "- I downloaded it and converted into a CSV File.\n",
    "\n",
    "- I need to make some changes to the CSV File to make the testing easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/wrong_words.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The correct word is the word that has a dollar sign at the start.\n",
    "\n",
    "- So the idea is that we want to make another column, that has the correct word for each misspelled word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$Albert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ameraca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amercia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word\n",
       "0   $Albert\n",
       "1        Ab\n",
       "2  $America\n",
       "3   Ameraca\n",
       "4   Amercia"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$Albert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ameraca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amercia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>$American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ameracan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>$April</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Apirl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word\n",
       "0    $Albert\n",
       "1         Ab\n",
       "2   $America\n",
       "3    Ameraca\n",
       "4    Amercia\n",
       "5  $American\n",
       "6   Ameracan\n",
       "7     $April\n",
       "8      Apirl"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_data = data[0:9]\n",
    "\n",
    "subset_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$manage'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Word\"][23551]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_words = []\n",
    "i = 0\n",
    "j = 1\n",
    "\n",
    "while j < data.shape[0] and i < data.shape[0]:\n",
    "\n",
    "    word1 = data[\"Word\"][i]\n",
    "    word2 = data[\"Word\"][j]\n",
    "    if \"$\" in word1:\n",
    "        if \"$\" in word2:\n",
    "            correct_word = word1.replace(\"$\", \"\")\n",
    "            correct_words += [correct_word for _ in range(j-i)]\n",
    "            i = j\n",
    "            j += 1\n",
    "        else:\n",
    "            j += 1\n",
    "\n",
    "\n",
    "if i < data.shape[0]:\n",
    "    word1 = data[\"Word\"][i+1]\n",
    "    correct_word = word1.replace(\"$\", \"\")\n",
    "    correct_words += [correct_word for _ in range(j-i)]\n",
    "    \n",
    "data[\"Correct_word\"] = correct_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Correct_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$Albert</td>\n",
       "      <td>Albert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab</td>\n",
       "      <td>Albert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$America</td>\n",
       "      <td>America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ameraca</td>\n",
       "      <td>America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amercia</td>\n",
       "      <td>America</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word Correct_word\n",
       "0   $Albert       Albert\n",
       "1        Ab       Albert\n",
       "2  $America      America\n",
       "3   Ameraca      America\n",
       "4   Amercia      America"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Will remove the rows that has the correct words, as there no need to have their own row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~data[\"Word\"].str.contains(\"\\$\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Correct_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab</td>\n",
       "      <td>Albert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ameraca</td>\n",
       "      <td>America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amercia</td>\n",
       "      <td>America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ameracan</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Apirl</td>\n",
       "      <td>April</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word Correct_word\n",
       "1        Ab       Albert\n",
       "3   Ameraca      America\n",
       "4   Amercia      America\n",
       "6  Ameracan     American\n",
       "8     Apirl        April"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2:- CHOOSING THE METRICS \n",
    "\n",
    "The chosen Metrics:-\n",
    " \n",
    "1) Accuracy: Accuracy is a straightforward and intuitive metric that directly reflects how often the spell checker provides the correct correction. It’s useful as an overall performance indicator, providing a clear picture of the tool’s effectiveness. I chose Accuracy because it offers a simple yet comprehensive assessment of the spell checker’s ability to make the right corrections without needing to analyze the rank or multiple options.\n",
    "\n",
    "2) Mean Reciprocal Rank (MRR): MRR is particularly beneficial for spell checkers that generate multiple suggestions, as it rewards tools that place the correct answer higher on the list. This metric is ideal for applications where the user can choose from several suggested corrections. I chose MRR because it captures not only if the correct answer is present but also how well-ranked it is, adding a layer of quality assessment to the tool’s suggestions.\n",
    "\n",
    "Reasons for Choosing These Over Other Metrics:\n",
    "\n",
    "- Precision & Recall: While these metrics are useful for evaluating over-correction and under-correction, they are more suited for applications where false positives and false negatives carry different weights, such as in classification tasks. For spell checking, Accuracy and MRR provide a more holistic view of performance.\n",
    "- Edit Distance: This metric measures the number of changes needed to transform the misspelled word into the correct word. However, it may not fully capture the quality of the spell checker’s suggestions, especially when multiple suggestions are offered. MRR, in contrast, focuses on the rank of correct suggestions, which is more relevant for assessing user-facing spell checkers.\n",
    "These choices balance the need for an overall accuracy assessment (Accuracy) with a focus on ranking quality (MRR), making them well-suited to evaluating spell checkers in a practical, user-oriented context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3:- CHOOSING THE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Error while downloading from https://cdn-lfs.hf.co/prithivida/grammar_error_correcter_v1/7a25e717ec2582f77c087d77bf7f09d866bb6ea63b1ff79a4fb17061a4b39c8d?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1731013390&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTAxMzM5MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9wcml0aGl2aWRhL2dyYW1tYXJfZXJyb3JfY29ycmVjdGVyX3YxLzdhMjVlNzE3ZWMyNTgyZjc3YzA4N2Q3N2JmN2YwOWQ4NjZiYjZlYTYzYjFmZjc5YTRmYjE3MDYxYTRiMzljOGQ%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=CataPlwBG5ZwMQj%7Ec2g3EmDmka-RCODA3zMVocKz3TIPvywqglJCQCglYiPuZrPwX6dwZ5LDes4GmJJp5wVr4i9zLuXzppfAhOu5iQm5HceH1W81yHlN4CjG0Bd95cZXFCvbEKktTykKm6vKJbcO%7EaUnvebcjf58k%7EGHt0T8S7qQidDp%7ESO2ampEud1TpeAI6KksW1poSStpkEV1Fhkwf-fHLrhfcl9vnLEPWcOlD6dfI1uqPkLVKlx%7EPqCrZtWkbytwCvIyFr%7EyPzTDxm6eDTXwX7uURCBPhAv6eGCzwav2GFV10scsZpL0oN71Mk-URGPvimuZs%7EpY3jTnOPvJSA__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "C:\\Users\\abdel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\abdel\\.cache\\huggingface\\hub\\models--prithivida--grammar_error_correcter_v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "# Load a grammar and spell correction model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"prithivida/grammar_error_correcter_v1\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"prithivida/grammar_error_correcter_v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Amerca, Corrected: Amerca\n",
      "Original: Aperl, Corrected: Aperl.\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"Amerca\", \"Aperl\"]\n",
    "\n",
    "for sentence in sentences:\n",
    "    # Encode and generate correction\n",
    "    inputs = tokenizer.encode(\"gec: \" + sentence, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs, max_length=128, num_beams=5, early_stopping=True)\n",
    "    corrected_sentence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(f\"Original: {sentence}, Corrected: {corrected_sentence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\abdel\\.cache\\huggingface\\hub\\models--google--flan-t5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load T5 model for spell correction\n",
    "tokenizer_T5 = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model_T5 = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Amerca is a continet., Corrected: America is a continent.\n",
      "Original: Aperil is in the sping., Corrected: Aperil is in the sping.\n"
     ]
    }
   ],
   "source": [
    "# Define a few sentences with spelling errors\n",
    "sentences = [\"Amerca is a continet.\", \"Aperil is in the sping.\"]\n",
    "\n",
    "for sentence in sentences:\n",
    "    # Use T5 for spell correction by framing the input with a prompt\n",
    "    inputs = tokenizer_T5(\"Correct the spelling: \" + sentence, return_tensors=\"pt\")\n",
    "    outputs = model_T5.generate(inputs.input_ids, max_length=50, num_beams=5, early_stopping=True)\n",
    "    corrected_sentence = tokenizer_T5.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(f\"Original: {sentence}, Corrected: {corrected_sentence}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
